{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MAC2(7).ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0729442d7a414e0db6cea9818bdf1dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_42964829aefb4e648e299746e29ecf6e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_84fb118a033d4e4ea822c8ed805c548a",
              "IPY_MODEL_bfc52f04962b42fe8a9ccca7933d7190",
              "IPY_MODEL_9d83886a9b764358ad8f1335e6866dd0"
            ]
          }
        },
        "42964829aefb4e648e299746e29ecf6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84fb118a033d4e4ea822c8ed805c548a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dc4f84bad4764dfcbad3bcc460d4b8ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1fe1d184ac6b40908b49bc5a1832b5cc"
          }
        },
        "bfc52f04962b42fe8a9ccca7933d7190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0a267ce54b9d4611a3289da8a3876df7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 707,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 707,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14b50a5bf81845e297f7ac9029c2fcfa"
          }
        },
        "9d83886a9b764358ad8f1335e6866dd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_70da98adf12444448a313bbb19b2b685",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 707/707 [00:00&lt;00:00, 24.1kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7639f4c582e24f86bc87e77108cfb5de"
          }
        },
        "dc4f84bad4764dfcbad3bcc460d4b8ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1fe1d184ac6b40908b49bc5a1832b5cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0a267ce54b9d4611a3289da8a3876df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14b50a5bf81845e297f7ac9029c2fcfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70da98adf12444448a313bbb19b2b685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7639f4c582e24f86bc87e77108cfb5de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8065337e8fa4368a751602777c1a920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_65562d6511504ae8927c5faf96897b41",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2ed5cf5a72f8431fb2eaea88969ad620",
              "IPY_MODEL_54c6e336f5a2413cbffc061946221082",
              "IPY_MODEL_ad38c3befea84d458c5a2eefa310d478"
            ]
          }
        },
        "65562d6511504ae8927c5faf96897b41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ed5cf5a72f8431fb2eaea88969ad620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4f4a153d7d6c49d69f5d4f5e31299356",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_49068377291f4e18a8f599e4e7ea9599"
          }
        },
        "54c6e336f5a2413cbffc061946221082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ab378a9f2f804f15a91f4860b5f74110",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 802243295,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 802243295,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c76fc79e2aa45c29f4cda56c74a7a3e"
          }
        },
        "ad38c3befea84d458c5a2eefa310d478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_96ffbb5177994254bd308dcdca8a9f73",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 765M/765M [00:13&lt;00:00, 61.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7ec05b5110734799a4022270f206b98a"
          }
        },
        "4f4a153d7d6c49d69f5d4f5e31299356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "49068377291f4e18a8f599e4e7ea9599": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab378a9f2f804f15a91f4860b5f74110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c76fc79e2aa45c29f4cda56c74a7a3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96ffbb5177994254bd308dcdca8a9f73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7ec05b5110734799a4022270f206b98a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGzbGifWz8so"
      },
      "source": [
        "# Flask(prepare model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctN3VZx3z7L1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ed2c6a3c-e1dd-4987-8c9e-8a47de26fd52"
      },
      "source": [
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(5000)\"))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://vl84za6sdcf-496ff2e9c6d22116-5000-colab.googleusercontent.com/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuJbJ21OwWEl",
        "outputId": "ae561163-fe2c-406b-e4bc-b4880cdd2155"
      },
      "source": [
        "!pip install flask_ngrok"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flask_ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (1.1.4)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.0.1)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask_ngrok) (2.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2.10)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFTdrR31yXKu",
        "outputId": "7a064584-6f75-4577-aaec-acd99bbcc9f0"
      },
      "source": [
        "!pip install -q transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.1 MB 12.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 59 kB 8.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 80.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 80.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 86.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sVdj3OJwdnv",
        "outputId": "9277a65b-564e-444e-b1c2-9cb4820ca59d"
      },
      "source": [
        "!pip install pyyaml==5.1\n",
        "# workaround: install old version of pytorch since detectron2 hasn't released packages for pytorch 1.9 (issue: https://github.com/facebookresearch/detectron2/issues/3158)\n",
        "!pip install torch==1.8.0+cu101 torchvision==0.9.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install detectron2 that matches pytorch 1.8\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "!pip install -q detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n",
        "# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 34.8 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 38.8 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 44.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40 kB 25.7 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 71 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 81 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 102 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 112 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 122 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 133 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 143 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 153 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 163 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 174 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 184 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 194 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 204 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 225 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 235 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 245 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 256 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 266 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 274 kB 14.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44092 sha256=e7d54bf8149c147b6a6d3405c484cc326f32f0add5bbe66c2ec57c8a83f8041b\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/f5/10/d00a2bd30928b972790053b5de0c703ca87324f3fead0f2fd9\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "Successfully installed pyyaml-5.1\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.0+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torch-1.8.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (763.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 763.5 MB 11 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.0+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.9.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 49.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu101) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu101) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0+cu101) (7.1.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu111\n",
            "    Uninstalling torch-1.9.0+cu111:\n",
            "      Successfully uninstalled torch-1.9.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0+cu111\n",
            "    Uninstalling torchvision-0.10.0+cu111:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.8.0+cu101 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.0+cu101 torchvision-0.9.0+cu101\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 729 kB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 23.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 74 kB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 130 kB 79.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 749 kB 81.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 743 kB 80.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 83.4 MB/s \n",
            "\u001b[?25h  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsaQCz8pxlja",
        "outputId": "da28009e-4c29-44a1-ff87-ccbd1a3c04fa"
      },
      "source": [
        "!pip install -q datasets\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install -q pytesseract\n",
        "model_checkpoint = \"microsoft/layoutlmv2-base-uncased\"\n",
        "batch_size = 16"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 290 kB 14.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 243 kB 84.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 68.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 78.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 192 kB 72.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 85.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 160 kB 77.6 MB/s \n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 0s (32.1 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 155219 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7Wu_q4Ixzja"
      },
      "source": [
        "from PIL import Image\n",
        "from transformers import LayoutLMv2FeatureExtractor\n",
        "\n",
        "feature_extractor = LayoutLMv2FeatureExtractor()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_ieK_a3x0Ls"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import LayoutLMv2Processor"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192,
          "referenced_widgets": [
            "0729442d7a414e0db6cea9818bdf1dba",
            "42964829aefb4e648e299746e29ecf6e",
            "84fb118a033d4e4ea822c8ed805c548a",
            "bfc52f04962b42fe8a9ccca7933d7190",
            "9d83886a9b764358ad8f1335e6866dd0",
            "dc4f84bad4764dfcbad3bcc460d4b8ac",
            "1fe1d184ac6b40908b49bc5a1832b5cc",
            "0a267ce54b9d4611a3289da8a3876df7",
            "14b50a5bf81845e297f7ac9029c2fcfa",
            "70da98adf12444448a313bbb19b2b685",
            "7639f4c582e24f86bc87e77108cfb5de",
            "c8065337e8fa4368a751602777c1a920",
            "65562d6511504ae8927c5faf96897b41",
            "2ed5cf5a72f8431fb2eaea88969ad620",
            "54c6e336f5a2413cbffc061946221082",
            "ad38c3befea84d458c5a2eefa310d478",
            "4f4a153d7d6c49d69f5d4f5e31299356",
            "49068377291f4e18a8f599e4e7ea9599",
            "ab378a9f2f804f15a91f4860b5f74110",
            "7c76fc79e2aa45c29f4cda56c74a7a3e",
            "96ffbb5177994254bd308dcdca8a9f73",
            "7ec05b5110734799a4022270f206b98a"
          ]
        },
        "id": "zfJ2Z_3Ix5NP",
        "outputId": "c6b6a3db-1530-4367-cfdb-8da356cc68f8"
      },
      "source": [
        "from transformers import AutoModelForQuestionAnswering\n",
        "model_checkpoint = \"microsoft/layoutlmv2-base-uncased\"\n",
        "QAmodel = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0729442d7a414e0db6cea9818bdf1dba",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/707 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8065337e8fa4368a751602777c1a920",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/765M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/layoutlmv2-base-uncased were not used when initializing LayoutLMv2ForQuestionAnswering: ['layoutlmv2.visual.backbone.bottom_up.res4.18.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.14.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.stem.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.14.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.14.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv2.norm.num_batches_tracked']\n",
            "- This IS expected if you are initializing LayoutLMv2ForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LayoutLMv2ForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LayoutLMv2ForQuestionAnswering were not initialized from the model checkpoint at microsoft/layoutlmv2-base-uncased and are newly initialized: ['layoutlmv2.visual_segment_embedding', 'qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbDRiZEzz2zK"
      },
      "source": [
        "# MAC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wY8l8Zm0Oih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8748d04a-57d3-43b1-b6c5-7d8296541ea7"
      },
      "source": [
        "from imageio import imread\n",
        "import torch\n",
        "import torchvision\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa_RRkVCUajx",
        "outputId": "b30fb723-4f03-4f40-be8b-1fd57ced84b4"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGaCt8R_k1cd",
        "outputId": "1f2d056f-56f8-4e33-e163-516d7bdaeda2"
      },
      "source": [
        "cd sample_data/"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J07urLxclE6w",
        "outputId": "85fccc5a-989a-4908-f28b-3f8edb5511bd"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anscombe.json\t\t      mnist_test.csv\n",
            "california_housing_test.csv   mnist_train_small.csv\n",
            "california_housing_train.csv  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9SqCW9ZlGSB",
        "outputId": "5276829e-e4e9-4a01-8c8c-cf584709ac53"
      },
      "source": [
        "!git clone https://github.com/LeoKingzc1/MAC_test.git"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MAC_test'...\n",
            "remote: Enumerating objects: 132, done.\u001b[K\n",
            "remote: Counting objects: 100% (132/132), done.\u001b[K\n",
            "remote: Compressing objects: 100% (130/130), done.\u001b[K\n",
            "remote: Total 132 (delta 37), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (132/132), 3.53 MiB | 14.57 MiB/s, done.\n",
            "Resolving deltas: 100% (37/37), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVcYHBxaORhv",
        "outputId": "80f15638-f4b2-4891-8945-77c8249f449e"
      },
      "source": [
        "! wget https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.zip"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-10 04:57:00--  https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.zip\n",
            "Resolving huggingface.co (huggingface.co)... 34.196.61.219, 54.83.132.138, 2600:1f18:147f:e850:64b4:e547:f3b6:c70d, ...\n",
            "Connecting to huggingface.co (huggingface.co)|34.196.61.219|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/stanfordnlp/glove/6471382cdd837544bf3ac72497a38715e845897d265b2b424b4761832009c837 [following]\n",
            "--2021-11-10 04:57:00--  https://cdn-lfs.huggingface.co/stanfordnlp/glove/6471382cdd837544bf3ac72497a38715e845897d265b2b424b4761832009c837\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 65.9.83.91, 65.9.83.15, 65.9.83.69, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|65.9.83.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182753 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  87.0MB/s    in 9.4s    \n",
            "\n",
            "2021-11-10 04:57:10 (87.4 MB/s) - ‘glove.6B.zip’ saved [862182753/862182753]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qycJ1HIlOU0t",
        "outputId": "3a06866a-c08c-49a5-f2b5-50aba6b5b9fa"
      },
      "source": [
        "!unzip '/content/sample_data/glove.6B.zip' -d'/content/sample_data/CLEVR_v1/data/glove'"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/sample_data/glove.6B.zip\n",
            "  inflating: /content/sample_data/CLEVR_v1/data/glove/glove.6B.100d.txt  \n",
            "  inflating: /content/sample_data/CLEVR_v1/data/glove/glove.6B.200d.txt  \n",
            "  inflating: /content/sample_data/CLEVR_v1/data/glove/glove.6B.300d.txt  \n",
            "  inflating: /content/sample_data/CLEVR_v1/data/glove/glove.6B.50d.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEhouz5mlIRi"
      },
      "source": [
        "# ! wget https://dl.fbaipublicfiles.com/clevr/CLEVR_v1.0.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-DW2rIglyJ4"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#!unzip '/content/sample_data/mac-network/CLEVR_v1.0.zip/' -d'/content/drive/My Drive/data'\n",
        "# !unzip CLEVR_v1.0.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGbJdp9qx43D"
      },
      "source": [
        "# !mv CLEVR_v1.0 CLEVR_v1\n",
        "# !mkdir CLEVR_v1/data\n",
        "# !mv CLEVR_v1/questions/* CLEVR_v1/data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pMmHGddTgVP"
      },
      "source": [
        "#Current version of Scipy has removed imread and imresize\n",
        "#Restore the previous version\n",
        "#pip install scipy==1.2.0\n",
        "#pip install scipy==1.0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTIdmGZ8TJ3I"
      },
      "source": [
        "#1.改写extract_features.py(rewrite 2Funcs(new scipy has no2Funcs below)):\n",
        "## 注释掉from scipy.misc import imread, imresize\n",
        "## 添加以下(调PIL包和定义两个方法)：\n",
        "## import imageio\n",
        "## import PIL\n",
        "## from PIL import Image\n",
        "## def imresize(img,img_size):\n",
        "##   return np.array(Image.fromarray(img).resize(img_size,PIL.Image.BICUBIC))\n",
        "## def imread(path):\n",
        "##   return (imageio.imread(path, pilmode='RGB'))\n",
        "##  改写以下(第90行出头)：\n",
        "### img = imread(path)\n",
        "### img = imresize(img, img_size)\n",
        "\n",
        "#2.将tensorflow 从version2 变 version1\n",
        "#复制下面两行到所有调TensorFlow的PY文件，替换掉import tensorflow as tf\n",
        "#包含mac_cell.py, main.py, mi_gru_cell.py, mi_lstm_cell.py, model.py, ops.py\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "#3.改写ops.py getKernel(有两处)\n",
        "#initializer = tf.keras.initializers.glorot_normal()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swNz4VKDw4Fv",
        "outputId": "66f4731c-3c12-4969-c633-7b5c20a6e1d0"
      },
      "source": [
        "#Train Feature extraction\n",
        "!python /content/sample_data/mac-network/extract_features.py --input_image_dir /content/sample_data/CLEVR_v1/images/train --output_h5_file /content/sample_data/CLEVR_v1/data/train.h5 --batch_size 1"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('/content/sample_data/CLEVR_v1/images/train/CLEVR_train_000000.png', 0)\n",
            "('/content/sample_data/CLEVR_v1/images/train/CLEVR_train_000007.png', 7)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-5d3b4d8f.pth\n",
            "100% 170M/170M [00:01<00:00, 89.5MB/s]\n",
            "/content/sample_data/mac-network/extract_features.py:64: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  image_batch = torch.autograd.Variable(image_batch, volatile=True)\n",
            "Processed 1 / 8 images\n",
            "Processed 2 / 8 images\n",
            "Processed 3 / 8 images\n",
            "Processed 4 / 8 images\n",
            "Processed 5 / 8 images\n",
            "Processed 6 / 8 images\n",
            "Processed 7 / 8 images\n",
            "Processed 8 / 8 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-ZDufETj5vA",
        "outputId": "a7e0a049-e148-49b8-db25-40080d9cc933"
      },
      "source": [
        "#Val Feature extraction\n",
        "!python /content/sample_data/mac-network/extract_features.py --input_image_dir /content/sample_data/CLEVR_v1/images/val --output_h5_file /content/sample_data/CLEVR_v1/data/val.h5 --batch_size 1"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('/content/sample_data/CLEVR_v1/images/val/CLEVR_val_000000.png', 0)\n",
            "('/content/sample_data/CLEVR_v1/images/val/CLEVR_val_000006.png', 6)\n",
            "/content/sample_data/mac-network/extract_features.py:64: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  image_batch = torch.autograd.Variable(image_batch, volatile=True)\n",
            "Processed 1 / 7 images\n",
            "Processed 2 / 7 images\n",
            "Processed 3 / 7 images\n",
            "Processed 4 / 7 images\n",
            "Processed 5 / 7 images\n",
            "Processed 6 / 7 images\n",
            "Processed 7 / 7 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obmruAu-j7y2",
        "outputId": "ef574eb0-1039-4aae-d2fc-6824bb6131e5"
      },
      "source": [
        "#Test Feature extraction\n",
        "!python /content/sample_data/mac-network/extract_features.py --input_image_dir /content/sample_data/CLEVR_v1/images/test --output_h5_file /content/sample_data/CLEVR_v1/data/test.h5 --batch_size 1"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('/content/sample_data/CLEVR_v1/images/test/CLEVR_test_000000.png', 0)\n",
            "('/content/sample_data/CLEVR_v1/images/test/CLEVR_test_000002.png', 2)\n",
            "/content/sample_data/mac-network/extract_features.py:64: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  image_batch = torch.autograd.Variable(image_batch, volatile=True)\n",
            "Processed 1 / 3 images\n",
            "Processed 2 / 3 images\n",
            "Processed 3 / 3 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSJ77--CcExg",
        "outputId": "47173b65-9bfb-4aa0-e0e0-be086367c85d"
      },
      "source": [
        "#Training\n",
        "!python /content/sample_data/mac-network/main.py --expName \"clevrExperiment\" --train --testedNum 100 --epochs 30 --netLength 4 @/content/sample_data/mac-network/configs/args.txt"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "\u001b[1mPreprocess data...\u001b[0m\n",
            "\u001b[1mLoading data...\u001b[0m\n",
            "\rPreprocessing:   0% 0/155 [00:00<?, ?it/s]\rPreprocessing: 100% 155/155 [00:00<00:00, 37954.18it/s]\n",
            "\rPreprocessing:   0% 0/70 [00:00<?, ?it/s]\rPreprocessing: 100% 70/70 [00:00<00:00, 87459.42it/s]\n",
            "\rPreprocessing:   0% 0/67 [00:00<?, ?it/s]\rPreprocessing: 100% 67/67 [00:00<00:00, 56091.49it/s]\n",
            "took 0.04 seconds\n",
            "\u001b[1mLoading word vectors...\u001b[0m\n",
            "59\n",
            "{'<PAD>': 0, '<UNK>': 1, '<START>': 2, '<END>': 3, 'what': 4, 'titles': 5, 'are': 6, 'left': 7, 'of': 8, 'this': 9, 'page': 10, 'top': 11, 'bottom': 12, 'right': 13, 'is': 14, 'text': 15, 'about': 16, 'on': 17, 'the': 18, 'table': 19, 'captions': 20, 'list': 21, 'figure': 22, 'there': 23, 'existing': 24, 'a': 25, 'content': 26, 'that': 27, 'journal': 28, 'component': 29, '0': 30, 'and': 31, '1': 32, 'if': 33, 'more': 34, 'than': 35, 'one': 36, ',': 37, 'total': 38, 'count': 39, 'both': 40, '2': 41, ';': 42, 'its': 43, 'figure_caption': 44, '3': 45, '0s': 46, 'top-left': 47, 'it': 48, '1s': 49, 'bottom-left': 50, '3s': 51, 's': 52, 'top-right': 53, '2s': 54, 'how': 55, 'many': 56, 'bottom-right': 57, 'any': 58, '4s': 59, 'function': 60, 'title': 61, 'components': 62, 'figures': 63, 'texts': 64, 'figure_captions': 65}\n",
            "66\n",
            "{'Abstract': 0, 'There is no title in the bottom left of page': 1, 'This page is Centered layout': 2, 'There is no title in the top right of page': 3, 'There is no title in the bottom right of page': 4, 'It is unclear': 5, 'Background,Filarial parasites and tissue preparation': 6, 'There is no table_caption in the right of page': 7, 'There is no table_caption in the top right of page': 8, 'There is no table_caption in the bottom right of page': 9, 'There is no figure_caption in the left of page': 10, 'There is no figure_caption in the top left of page': 11, 'There is no figure_caption in the bottom left of page': 12, 'There is no figure_caption in the right of page': 13, 'There is no figure_caption in the top right of page': 14, 'There is no figure_caption in the bottom right of page': 15, 'No (we cannot find the thing meet the requirement)': 16, 'text 1': 17, 'Yes': 18, 'journal': 19, 'No title': 20, 6: 21, 2: 22, 4: 23, 'Yes, it is ': 24, 'There is no title in the left of page': 25, 'There is no title in the top left of page': 26, 'There is no title in the right of page': 27, 'text 0': 28, 'Tissue localization of collagenase and leucine aminopeptidase in the\\nbovine filarial parasite Setaria cervi,Erhöhte urogenitale Fistelrate nach Bevacizumab bei Patientinnen mit rezidiviertem Zervixkarzinom nach primärer Behandlung mit definitiver Radiochemotherapie und bildgesteuerter adaptiver Brachytherapie,Zusammenfassung': 29, 'Zusammenfassung,Abstract': 30, 'Patients,Materials and methods': 31, 'text 6': 32, 'text 9': 33, 'Conclusion': 34}\n",
            "35\n",
            "{'<PAD>': 0, '<UNK>': 1, '<START>': 2, '<END>': 3, 'what': 4, 'titles': 5, 'are': 6, 'left': 7, 'of': 8, 'this': 9, 'page': 10, 'Abstract': 11, 'top': 12, 'bottom': 13, 'There is no title in the bottom left of page': 14, 'right': 15, 'This page is Centered layout': 16, 'There is no title in the top right of page': 17, 'There is no title in the bottom right of page': 18, 'is': 19, 'text': 20, 'about': 21, 'on': 22, 'the': 23, 'It is unclear': 24, 'Background,Filarial parasites and tissue preparation': 25, 'table': 26, 'captions': 27, 'There is no table_caption in the right of page': 28, 'There is no table_caption in the top right of page': 29, 'There is no table_caption in the bottom right of page': 30, 'list': 31, 'figure': 32, 'There is no figure_caption in the left of page': 33, 'There is no figure_caption in the top left of page': 34, 'There is no figure_caption in the bottom left of page': 35, 'There is no figure_caption in the right of page': 36, 'There is no figure_caption in the top right of page': 37, 'There is no figure_caption in the bottom right of page': 38, 'there': 39, 'existing': 40, 'a': 41, 'content': 42, 'that': 43, 'journal': 44, 'component': 45, '0': 46, 'and': 47, '1': 48, 'if': 49, 'more': 50, 'than': 51, 'one': 52, ',': 53, 'total': 54, 'count': 55, 'No (we cannot find the thing meet the requirement)': 56, 'both': 57, '2': 58, 'text 1': 59, ';': 60, 'its': 61, 'figure_caption': 62, '3': 63, '0s': 64, 'top-left': 65, 'it': 66, '1s': 67, 'bottom-left': 68, '3s': 69, 's': 70, 'top-right': 71, 'Yes': 72, '2s': 73, 'how': 74, 'many': 75, 'bottom-right': 76, 'any': 77, '4s': 78, 'function': 79, 'title': 80, 'No title': 81, 'components': 82, 6: 83, 'figures': 84, 2: 85, 'texts': 86, 4: 87, 'figure_captions': 88, 'Yes, it is ': 89, 'There is no title in the left of page': 90, 'There is no title in the top left of page': 91, 'There is no title in the right of page': 92, 'text 0': 93, 'Tissue localization of collagenase and leucine aminopeptidase in the\\nbovine filarial parasite Setaria cervi,Erhöhte urogenitale Fistelrate nach Bevacizumab bei Patientinnen mit rezidiviertem Zervixkarzinom nach primärer Behandlung mit definitiver Radiochemotherapie und bildgesteuerter adaptiver Brachytherapie,Zusammenfassung': 94, 'Zusammenfassung,Abstract': 95, 'Patients,Materials and methods': 96, 'text 6': 97, 'text 9': 98, 'Conclusion': 99}\n",
            "100\n",
            "took 9.77 seconds\n",
            "\u001b[1mVectorizing data...\u001b[0m\n",
            "took 0.00 seconds\n",
            "took \u001b[1m\u001b[34m9.82\u001b[0m seconds\n",
            "\u001b[1mBuilding model...\u001b[0m\n",
            "/content/sample_data/mac-network/ops.py:771: UserWarning: `tf.nn.rnn_cell.BasicRNNCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.SimpleRNNCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  cell = cells[cellType](hDim, reuse = reuse, activation = activation)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:459: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  shape=[input_depth + self._num_units, self._num_units])\n",
            "/usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:463: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  initializer=tf.compat.v1.zeros_initializer(dtype=self.dtype))\n",
            "took \u001b[1m\u001b[34m3.66\u001b[0m seconds\n",
            "2021-11-10 05:01:08.257685: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[1m\u001b[34mInitializing weights\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 1...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m 1\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.03\u001b[0m (0.00+0.03), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0041\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m2.4955\u001b[0m, avA = \u001b[1m\u001b[31m0.4968\u001b[0m, g = 0.2184, emL = 2.1234, emA = 0.5648; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m 1\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m3.6842\u001b[0m, a = \u001b[1m\u001b[34m0.0000\u001b[0m, avL = \u001b[1m\u001b[34m2.8487\u001b[0m, avA = \u001b[1m\u001b[31m0.5900\u001b[0m, g = -1.0000, emL = 2.9194, emA = 0.4996; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m 1\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m3.0522\u001b[0m, a = \u001b[1m\u001b[34m0.0000\u001b[0m, avL = \u001b[1m\u001b[34m3.1050\u001b[0m, avA = \u001b[1m\u001b[31m0.4857\u001b[0m, g = -1.0000, emL = 3.1524, emA = 0.3734; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 26.05 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m2.495499449056543\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.4967741935483871\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m2.8487472486495973\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m0.59\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m3.1049505165645055\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.4857142857142857\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 2...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m 2\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.03\u001b[0m (0.00+0.03), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.3954\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.4141\u001b[0m, avA = \u001b[1m\u001b[31m0.6839\u001b[0m, g = 19.5494, emL = 1.5092, emA = 0.6748; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m 2\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m2.9470\u001b[0m, a = \u001b[1m\u001b[34m0.0000\u001b[0m, avL = \u001b[1m\u001b[34m2.0809\u001b[0m, avA = \u001b[1m\u001b[31m0.5900\u001b[0m, g = -1.0000, emL = 2.2929, emA = 0.5119; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m 2\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m1.5850\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m2.5414\u001b[0m, avA = \u001b[1m\u001b[31m0.4857\u001b[0m, g = -1.0000, emL = 2.9585, emA = 0.3550; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.45 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m1.41411493727252\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.6838709677419355\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m2.080944474339485\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m0.59\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m2.5414432747023445\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.4857142857142857\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 3...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m 3\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.03\u001b[0m (0.00+0.03), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m5.2640\u001b[0m, a = \u001b[1m\u001b[34m0.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.1407\u001b[0m, avA = \u001b[1m\u001b[31m0.7548\u001b[0m, g = 61.9264, emL = 1.1956, emA = 0.7174; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m 3\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m3.2060\u001b[0m, a = \u001b[1m\u001b[34m0.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.4936\u001b[0m, avA = \u001b[1m\u001b[31m0.6200\u001b[0m, g = -1.0000, emL = 1.3165, emA = 0.6818; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m 3\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.7478\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m2.1061\u001b[0m, avA = \u001b[1m\u001b[31m0.4857\u001b[0m, g = -1.0000, emL = 2.3194, emA = 0.3583; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.36 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m1.140710795472478\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.7548387096774194\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m1.4936178612709046\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m0.62\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m2.106145988191877\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.4857142857142857\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 4...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m 4\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.03\u001b[0m (0.00+0.03), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0049\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.9571\u001b[0m, avA = \u001b[1m\u001b[31m0.7806\u001b[0m, g = 0.2382, emL = 1.1273, emA = 0.7190; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m 4\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.1709\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.1228\u001b[0m, avA = \u001b[1m\u001b[31m0.7800\u001b[0m, g = -1.0000, emL = 1.0272, emA = 0.7801; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m 4\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m2.1716\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.8598\u001b[0m, avA = \u001b[1m\u001b[31m0.6286\u001b[0m, g = -1.0000, emL = 1.4669, emA = 0.7266; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.44 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.9571460158350097\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.7806451612903226\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m1.1227556566894055\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m0.78\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.8597768926194735\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.6285714285714286\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 5...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m 5\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.03\u001b[0m (0.00+0.03), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0003\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.7747\u001b[0m, avA = \u001b[1m\u001b[31m0.8000\u001b[0m, g = 0.0137, emL = 0.6805, emA = 0.8072; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m 5\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.02\u001b[0m (0.00+0.02), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0790\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.8802\u001b[0m, avA = \u001b[1m\u001b[31m0.8200\u001b[0m, g = -1.0000, emL = 0.7295, emA = 0.8636; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m 5\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m2.0461\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.7136\u001b[0m, avA = \u001b[1m\u001b[31m0.6857\u001b[0m, g = -1.0000, emL = 2.7599, emA = 0.5571; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.38 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.7747025257090554\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.8\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.8802136613428593\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m0.82\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.713641832130296\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.6857142857142857\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 6...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m 6\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.03\u001b[0m (0.00+0.03), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0173\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.6692\u001b[0m, avA = \u001b[1m\u001b[31m0.8129\u001b[0m, g = 1.0204, emL = 0.5711, emA = 0.8394; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m 6\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.02\u001b[0m (0.00+0.02), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0291\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.7015\u001b[0m, avA = \u001b[1m\u001b[31m0.8600\u001b[0m, g = -1.0000, emL = 0.5525, emA = 0.9031; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m 6\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m5.2387\u001b[0m, a = \u001b[1m\u001b[34m0.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.6197\u001b[0m, avA = \u001b[1m\u001b[31m0.7143\u001b[0m, g = -1.0000, emL = 3.0288, emA = 0.5516; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.38 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.6691837291587643\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.8129032258064516\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.7014949718490243\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m0.86\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.619676147906908\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.7142857142857143\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 7...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m 7\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.03\u001b[0m (0.00+0.03), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0007\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.6358\u001b[0m, avA = \u001b[1m\u001b[31m0.8452\u001b[0m, g = 0.0401, emL = 0.6817, emA = 0.8436; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m 7\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m1.5301\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.5728\u001b[0m, avA = \u001b[1m\u001b[31m0.8900\u001b[0m, g = -1.0000, emL = 0.5169, emA = 0.9070; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m 7\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m8.7879\u001b[0m, a = \u001b[1m\u001b[34m0.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.5651\u001b[0m, avA = \u001b[1m\u001b[31m0.7286\u001b[0m, g = -1.0000, emL = 1.3402, emA = 0.7659; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.32 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.6357709628462489\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.8451612903225807\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.5727929356880486\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m0.89\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.5650676385632583\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.7285714285714285\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 8...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m 8\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.03\u001b[0m (0.00+0.03), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0037\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.6394\u001b[0m, avA = \u001b[1m\u001b[31m0.8323\u001b[0m, g = 0.1868, emL = 0.7705, emA = 0.8267; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m 8\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.2038\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.4712\u001b[0m, avA = \u001b[1m\u001b[31m0.8900\u001b[0m, g = -1.0000, emL = 0.6368, emA = 0.7635; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m 8\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m1.4597\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.5264\u001b[0m, avA = \u001b[1m\u001b[31m0.7286\u001b[0m, g = -1.0000, emL = 1.1033, emA = 0.7901; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.40 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.639436499338522\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.832258064516129\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.4711574426293373\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m0.89\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.5263677342927882\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.7285714285714285\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 9...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m 9\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.03\u001b[0m (0.00+0.03), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0000\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.6202\u001b[0m, avA = \u001b[1m\u001b[31m0.8645\u001b[0m, g = 0.0004, emL = 0.7551, emA = 0.8493; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m 9\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0980\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.3890\u001b[0m, avA = \u001b[1m\u001b[31m0.8900\u001b[0m, g = -1.0000, emL = 0.3889, emA = 0.8763; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m 9\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.4833\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.4920\u001b[0m, avA = \u001b[1m\u001b[31m0.7286\u001b[0m, g = -1.0000, emL = 1.0405, emA = 0.7978; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.46 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.6202485980937325\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.864516129032258\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.3889768386207288\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m0.89\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.4919818625718888\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.7285714285714285\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 10...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m10\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.03\u001b[0m (0.00+0.03), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0000\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.4710\u001b[0m, avA = \u001b[1m\u001b[31m0.8581\u001b[0m, g = 0.0020, emL = 0.5067, emA = 0.8453; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m10\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0003\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.3268\u001b[0m, avA = \u001b[1m\u001b[31m0.9000\u001b[0m, g = -1.0000, emL = 0.2565, emA = 0.9154; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m10\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m12.1631\u001b[0m, a = \u001b[1m\u001b[34m0.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.5006\u001b[0m, avA = \u001b[1m\u001b[31m0.7286\u001b[0m, g = -1.0000, emL = 4.0975, emA = 0.5357; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.41 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.4710467478441437\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.8580645161290322\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.32677901890463545\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m0.9\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.5005631335478808\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.7285714285714285\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 11...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m11\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.04\u001b[0m (0.00+0.04), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0016\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.4020\u001b[0m, avA = \u001b[1m\u001b[31m0.9032\u001b[0m, g = 0.1462, emL = 0.6748, emA = 0.8554; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m11\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0017\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.2653\u001b[0m, avA = \u001b[1m\u001b[31m0.9200\u001b[0m, g = -1.0000, emL = 0.2375, emA = 0.9379; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m11\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0486\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.5004\u001b[0m, avA = \u001b[1m\u001b[31m0.7571\u001b[0m, g = -1.0000, emL = 1.0689, emA = 0.8131; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.38 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.40198237136825543\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.9032258064516129\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.26525716061762067\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m0.92\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.50036695965599\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.7571428571428571\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 12...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m12\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.03\u001b[0m (0.00+0.03), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0020\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.3741\u001b[0m, avA = \u001b[1m\u001b[31m0.9032\u001b[0m, g = 0.2329, emL = 0.3072, emA = 0.9117; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m12\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0025\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.2186\u001b[0m, avA = \u001b[1m\u001b[31m0.9500\u001b[0m, g = -1.0000, emL = 0.2311, emA = 0.9407; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m12\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m13.2706\u001b[0m, a = \u001b[1m\u001b[34m0.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.5023\u001b[0m, avA = \u001b[1m\u001b[31m0.8000\u001b[0m, g = -1.0000, emL = 1.5407, emA = 0.8526; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.40 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.3741371028422983\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.9032258064516129\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.21856460284090645\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m0.95\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.502323369406596\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.8\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 13...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m13\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.03\u001b[0m (0.00+0.03), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0018\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.2986\u001b[0m, avA = \u001b[1m\u001b[31m0.9097\u001b[0m, g = 0.2494, emL = 0.3830, emA = 0.8995; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m13\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0012\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.1816\u001b[0m, avA = \u001b[1m\u001b[31m0.9600\u001b[0m, g = -1.0000, emL = 0.1359, emA = 0.9758; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m13\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.2992\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.5207\u001b[0m, avA = \u001b[1m\u001b[31m0.8000\u001b[0m, g = -1.0000, emL = 1.0968, emA = 0.8521; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.38 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.2986328744070118\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.9096774193548387\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.18159303304330934\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m0.96\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.5206941592760683\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.8\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 14...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m14\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.03\u001b[0m (0.00+0.03), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.4588\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.2762\u001b[0m, avA = \u001b[1m\u001b[31m0.9097\u001b[0m, g = 26.3631, emL = 0.1592, emA = 0.9467; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m14\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0056\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.1543\u001b[0m, avA = \u001b[1m\u001b[31m0.9600\u001b[0m, g = -1.0000, emL = 0.1915, emA = 0.9363; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m14\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0015\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.5679\u001b[0m, avA = \u001b[1m\u001b[31m0.8143\u001b[0m, g = -1.0000, emL = 1.2974, emA = 0.8355; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.35 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.27618717686040295\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.9096774193548387\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.15433105475301317\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m0.96\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.5678503514252953\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.8142857142857143\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 15...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m15\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.04\u001b[0m (0.00+0.04), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0000\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.3206\u001b[0m, avA = \u001b[1m\u001b[31m0.9226\u001b[0m, g = 0.0001, emL = 0.3799, emA = 0.9258; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m15\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0032\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.1265\u001b[0m, avA = \u001b[1m\u001b[31m0.9800\u001b[0m, g = -1.0000, emL = 0.1080, emA = 0.9826; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m15\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m0.0001\u001b[0m, l = \u001b[1m\u001b[34m0.0003\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.6214\u001b[0m, avA = \u001b[1m\u001b[31m0.8143\u001b[0m, g = -1.0000, emL = 2.9493, emA = 0.6296; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.35 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.32060979058039246\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.9225806451612903\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.1264651584908131\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m0.98\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.6214165528552258\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.8142857142857143\u001b[0m\n",
            "\u001b[31mReducing LR to 5e-05\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 16...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m16\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.03\u001b[0m (0.00+0.03), lr \u001b[1m5e-05\u001b[0m, l = \u001b[1m\u001b[34m0.0006\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.1697\u001b[0m, avA = \u001b[1m\u001b[31m0.9613\u001b[0m, g = 0.0327, emL = 0.1923, emA = 0.9692; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m16\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m5e-05\u001b[0m, l = \u001b[1m\u001b[34m0.0003\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.1031\u001b[0m, avA = \u001b[1m\u001b[31m0.9800\u001b[0m, g = -1.0000, emL = 0.1208, emA = 0.9738; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m16\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m5e-05\u001b[0m, l = \u001b[1m\u001b[34m12.5530\u001b[0m, a = \u001b[1m\u001b[34m0.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.6546\u001b[0m, avA = \u001b[1m\u001b[31m0.8286\u001b[0m, g = -1.0000, emL = 1.6121, emA = 0.8556; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.31 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.16971314084767528\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.9612903225806452\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.10311555157235261\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m0.98\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.6545968308721577\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.8285714285714286\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 17...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m17\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.04\u001b[0m (0.00+0.04), lr \u001b[1m5e-05\u001b[0m, l = \u001b[1m\u001b[34m0.0000\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.1103\u001b[0m, avA = \u001b[1m\u001b[31m0.9677\u001b[0m, g = 0.0016, emL = 0.2024, emA = 0.9679; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m17\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m5e-05\u001b[0m, l = \u001b[1m\u001b[34m0.0001\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0842\u001b[0m, avA = \u001b[1m\u001b[31m0.9800\u001b[0m, g = -1.0000, emL = 0.1173, emA = 0.9776; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m17\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m5e-05\u001b[0m, l = \u001b[1m\u001b[34m0.0001\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.6824\u001b[0m, avA = \u001b[1m\u001b[31m0.8286\u001b[0m, g = -1.0000, emL = 1.1051, emA = 0.8955; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.26 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.1103046165042446\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.967741935483871\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.08419194554973643\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m0.98\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.6824266323460115\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.8285714285714286\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 18...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m18\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.04\u001b[0m (0.00+0.04), lr \u001b[1m5e-05\u001b[0m, l = \u001b[1m\u001b[34m0.0005\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0849\u001b[0m, avA = \u001b[1m\u001b[31m0.9548\u001b[0m, g = 0.0523, emL = 0.0925, emA = 0.9494; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m18\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m5e-05\u001b[0m, l = \u001b[1m\u001b[34m0.0016\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0648\u001b[0m, avA = \u001b[1m\u001b[31m0.9900\u001b[0m, g = -1.0000, emL = 0.0504, emA = 0.9933; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m18\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m5e-05\u001b[0m, l = \u001b[1m\u001b[34m0.0002\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.6911\u001b[0m, avA = \u001b[1m\u001b[31m0.8429\u001b[0m, g = -1.0000, emL = 1.4794, emA = 0.8630; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.38 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.08487797936389298\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.9548387096774194\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.06483102212056607\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m0.99\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.6910742874083422\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.8428571428571429\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 19...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m19\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.02\u001b[0m (0.00+0.02), lr \u001b[1m5e-05\u001b[0m, l = \u001b[1m\u001b[34m0.0004\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.1009\u001b[0m, avA = \u001b[1m\u001b[31m0.9871\u001b[0m, g = 0.0271, emL = 0.1231, emA = 0.9793; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m19\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m5e-05\u001b[0m, l = \u001b[1m\u001b[34m0.0001\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0488\u001b[0m, avA = \u001b[1m\u001b[31m0.9900\u001b[0m, g = -1.0000, emL = 0.0329, emA = 0.9934; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m19\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m5e-05\u001b[0m, l = \u001b[1m\u001b[34m0.0002\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.7034\u001b[0m, avA = \u001b[1m\u001b[31m0.8429\u001b[0m, g = -1.0000, emL = 1.3600, emA = 0.8735; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.28 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.10086118031970227\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.9870967741935484\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.048830901352738036\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m0.99\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.7033556843961768\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.8428571428571429\u001b[0m\n",
            "\u001b[31mReducing LR to 2.5e-05\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 20...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m20\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.02\u001b[0m (0.00+0.02), lr \u001b[1m2.5e-05\u001b[0m, l = \u001b[1m\u001b[34m0.0002\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0290\u001b[0m, avA = \u001b[1m\u001b[31m0.9935\u001b[0m, g = 0.0153, emL = 0.0167, emA = 0.9967; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m20\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m2.5e-05\u001b[0m, l = \u001b[1m\u001b[34m0.0004\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0343\u001b[0m, avA = \u001b[1m\u001b[31m0.9900\u001b[0m, g = -1.0000, emL = 0.0444, emA = 0.9846; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m20\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m2.5e-05\u001b[0m, l = \u001b[1m\u001b[34m0.0008\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.7044\u001b[0m, avA = \u001b[1m\u001b[31m0.8429\u001b[0m, g = -1.0000, emL = 1.2436, emA = 0.6581; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.32 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.02901970168699466\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.9935483870967742\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.03430490646376285\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m0.99\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.7043649744791505\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.8428571428571429\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 21...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m21\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.03\u001b[0m (0.00+0.03), lr \u001b[1m2.5e-05\u001b[0m, l = \u001b[1m\u001b[34m0.0003\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0185\u001b[0m, avA = \u001b[1m\u001b[31m0.9935\u001b[0m, g = 0.0235, emL = 0.0130, emA = 0.9977; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m21\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m2.5e-05\u001b[0m, l = \u001b[1m\u001b[34m0.0001\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0239\u001b[0m, avA = \u001b[1m\u001b[31m0.9900\u001b[0m, g = -1.0000, emL = 0.0095, emA = 0.9971; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m21\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m2.5e-05\u001b[0m, l = \u001b[1m\u001b[34m17.0062\u001b[0m, a = \u001b[1m\u001b[34m0.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.7093\u001b[0m, avA = \u001b[1m\u001b[31m0.8571\u001b[0m, g = -1.0000, emL = 1.4115, emA = 0.8780; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.33 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.018497169156481804\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.9935483870967742\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.023899505610752526\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m0.99\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.7092936321757277\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.8571428571428571\u001b[0m\n",
            "\u001b[31mReducing LR to 1.25e-05\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 22...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m22\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.02\u001b[0m (0.00+0.02), lr \u001b[1m1.25e-05\u001b[0m, l = \u001b[1m\u001b[34m0.0000\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0217\u001b[0m, avA = \u001b[1m\u001b[31m0.9935\u001b[0m, g = 0.0005, emL = 0.0187, emA = 0.9963; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m22\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m1.25e-05\u001b[0m, l = \u001b[1m\u001b[34m0.0004\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0141\u001b[0m, avA = \u001b[1m\u001b[31m0.9900\u001b[0m, g = -1.0000, emL = 0.0089, emA = 0.9966; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m22\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m1.25e-05\u001b[0m, l = \u001b[1m\u001b[34m0.0003\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.7177\u001b[0m, avA = \u001b[1m\u001b[31m0.8714\u001b[0m, g = -1.0000, emL = 1.2516, emA = 0.9044; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.36 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.02174729902026591\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.9935483870967742\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.014120693629675997\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m0.99\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.717706440202684\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.8714285714285714\u001b[0m\n",
            "\u001b[31mReducing LR to 6.25e-06\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 23...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m23\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.02\u001b[0m (0.00+0.02), lr \u001b[1m6.25e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0001\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0441\u001b[0m, avA = \u001b[1m\u001b[31m0.9935\u001b[0m, g = 0.0060, emL = 0.1121, emA = 0.9830; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m23\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m6.25e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0149\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0092\u001b[0m, avA = \u001b[1m\u001b[31m1.0000\u001b[0m, g = -1.0000, emL = 0.0129, emA = 1.0000; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m23\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m6.25e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0003\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.7370\u001b[0m, avA = \u001b[1m\u001b[31m0.8714\u001b[0m, g = -1.0000, emL = 1.3733, emA = 0.8930; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.38 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.04408502075160916\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.9935483870967742\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.009151922077539752\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m1.0\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.737041424121149\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.8714285714285714\u001b[0m\n",
            "\u001b[31mReducing LR to 3.125e-06\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 24...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m24\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.03\u001b[0m (0.00+0.03), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0000\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0231\u001b[0m, avA = \u001b[1m\u001b[31m0.9935\u001b[0m, g = 0.0000, emL = 0.0210, emA = 0.9940; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m24\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0000\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0058\u001b[0m, avA = \u001b[1m\u001b[31m1.0000\u001b[0m, g = -1.0000, emL = 0.0042, emA = 1.0000; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m24\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0000\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.7515\u001b[0m, avA = \u001b[1m\u001b[31m0.8714\u001b[0m, g = -1.0000, emL = 1.3494, emA = 0.9006; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.33 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.023098993595482214\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.9935483870967742\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.005792233581414834\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m1.0\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.751548191787437\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.8714285714285714\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 25...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m25\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.03\u001b[0m (0.00+0.03), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0002\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0182\u001b[0m, avA = \u001b[1m\u001b[31m0.9935\u001b[0m, g = 0.0168, emL = 0.0064, emA = 0.9985; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m25\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0004\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0038\u001b[0m, avA = \u001b[1m\u001b[31m1.0000\u001b[0m, g = -1.0000, emL = 0.0050, emA = 1.0000; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m25\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0007\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.7649\u001b[0m, avA = \u001b[1m\u001b[31m0.8714\u001b[0m, g = -1.0000, emL = 1.3716, emA = 0.8900; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.34 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.01824586887695386\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.9935483870967742\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.0037989555844048085\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m1.0\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.7648775605226807\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.8714285714285714\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 26...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m26\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.04\u001b[0m (0.00+0.04), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0000\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0223\u001b[0m, avA = \u001b[1m\u001b[31m0.9935\u001b[0m, g = 0.0003, emL = 0.0476, emA = 0.9849; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m26\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.02\u001b[0m (0.00+0.02), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0000\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0026\u001b[0m, avA = \u001b[1m\u001b[31m1.0000\u001b[0m, g = -1.0000, emL = 0.0022, emA = 1.0000; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m26\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0096\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.7786\u001b[0m, avA = \u001b[1m\u001b[31m0.8714\u001b[0m, g = -1.0000, emL = 1.3584, emA = 0.8995; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.36 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.02234540294004987\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.9935483870967742\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.0026058502121187386\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m1.0\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.778595868835282\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.8714285714285714\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 27...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m27\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.03\u001b[0m (0.00+0.03), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0001\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0215\u001b[0m, avA = \u001b[1m\u001b[31m0.9871\u001b[0m, g = 0.0051, emL = 0.0095, emA = 0.9971; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m27\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0000\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0019\u001b[0m, avA = \u001b[1m\u001b[31m1.0000\u001b[0m, g = -1.0000, emL = 0.0016, emA = 1.0000; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m27\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0001\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.7902\u001b[0m, avA = \u001b[1m\u001b[31m0.8571\u001b[0m, g = -1.0000, emL = 1.2507, emA = 0.8972; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.46 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.02154281307054434\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.9870967741935484\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.001883732451680018\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m1.0\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.79017972772651\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.8571428571428571\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 28...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m28\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.03\u001b[0m (0.00+0.03), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0000\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0229\u001b[0m, avA = \u001b[1m\u001b[31m0.9871\u001b[0m, g = 0.0002, emL = 0.0386, emA = 0.9795; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m28\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0001\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0014\u001b[0m, avA = \u001b[1m\u001b[31m1.0000\u001b[0m, g = -1.0000, emL = 0.0012, emA = 1.0000; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m28\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0028\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.8032\u001b[0m, avA = \u001b[1m\u001b[31m0.8429\u001b[0m, g = -1.0000, emL = 4.8454, emA = 0.6431; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.36 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.02292357671703316\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.9870967741935484\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.0014443257836028068\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m1.0\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.8031534570760999\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.8428571428571429\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 29...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m29\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.03\u001b[0m (0.00+0.03), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0000\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0189\u001b[0m, avA = \u001b[1m\u001b[31m0.9935\u001b[0m, g = 0.0014, emL = 0.0089, emA = 0.9972; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m29\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0000\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0012\u001b[0m, avA = \u001b[1m\u001b[31m1.0000\u001b[0m, g = -1.0000, emL = 0.0013, emA = 1.0000; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m29\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0287\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.8127\u001b[0m, avA = \u001b[1m\u001b[31m0.8429\u001b[0m, g = -1.0000, emL = 1.2116, emA = 0.8931; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.26 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.018878270231178728\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.9935483870967742\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.0011999471379635196\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m1.0\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.8126826339767572\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.8428571428571429\u001b[0m\n",
            "\u001b[1m\u001b[32mTraining epoch 30...\u001b[0m\n",
            "eb \u001b[1m\u001b[32m30\u001b[0m,154 (\u001b[1m\u001b[32m  155\u001b[0m /   155), t = \u001b[1m\u001b[32m0.03\u001b[0m (0.00+0.03), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0000\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0221\u001b[0m, avA = \u001b[1m\u001b[31m0.9871\u001b[0m, g = 0.0000, emL = 0.0157, emA = 0.9916; clevrExperiment\n",
            "\u001b[1mRestoring EMA weights\u001b[0m\n",
            "eb \u001b[1m\u001b[32m30\u001b[0m, 99 (\u001b[1m\u001b[32m  100\u001b[0m /   100), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0005\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0010\u001b[0m, avA = \u001b[1m\u001b[31m1.0000\u001b[0m, g = -1.0000, emL = 0.0007, emA = 1.0000; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m30\u001b[0m, 69 (\u001b[1m\u001b[32m   70\u001b[0m /    70), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m1.2680\u001b[0m, a = \u001b[1m\u001b[34m0.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.8209\u001b[0m, avA = \u001b[1m\u001b[31m0.8429\u001b[0m, g = -1.0000, emL = 1.6217, emA = 0.8559; clevrExperiment\n",
            "\u001b[1mRestoring standard weights\u001b[0m\n",
            "\n",
            "took 7.54 seconds\n",
            "Training Loss: \u001b[1m\u001b[35m0.022066573885409606\u001b[0m, Training accuracy: \u001b[1m\u001b[35m0.9870967741935484\u001b[0m\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.0010329062820371604\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m1.0\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.8208757911871478\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.8428571428571429\u001b[0m\n",
            "Training took 239.79 seconds (29 epochs)\n",
            "\u001b[1m\u001b[37mDone!\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw1Dpb9PaPCy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51040848-f83e-4198-a895-14352e2043eb"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "saver1 =tf.train.import_meta_graph('/content/sample_data/weights/clevrExperiment/weights30.ckpt.meta')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlFNairfgYE7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9da5715-e4f1-432d-a47f-88500544877a"
      },
      "source": [
        "saver1"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.saver.Saver at 0x7f923e23f7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqySiOYDmprz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce7SSv05GRqe",
        "outputId": "5da98b6d-a336-4078-b0fe-db647a52991a"
      },
      "source": [
        "#模型的变体，可以不run\n",
        "!python /content/sample_data/mac-network/main.py --expName \"experiment1\" --train --testedNum 1000 --epochs 25 --netLength 6 @/content/sample_data/mac-network/configs/args2.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "\u001b[1mPreprocess data...\u001b[0m\n",
            "\u001b[1mLoading data...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5uZQoEIHCmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd4c4d4a-138d-44f1-a77c-183f65eb860e"
      },
      "source": [
        "#Evaluation\n",
        "!python /content/sample_data/mac-network/main.py --expName \"clevrExperiment\" --finalTest --testedNum 50 --netLength 4 -r --getPreds --getAtt @/content/sample_data/mac-network/configs/args.txt"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "\u001b[1mPreprocess data...\u001b[0m\n",
            "\u001b[1mLoading data...\u001b[0m\n",
            "took 0.01 seconds\n",
            "\u001b[1mLoading word vectors...\u001b[0m\n",
            "59\n",
            "{'<PAD>': 0, '<UNK>': 1, '<START>': 2, '<END>': 3, 'what': 4, 'titles': 5, 'are': 6, 'left': 7, 'of': 8, 'this': 9, 'page': 10, 'top': 11, 'bottom': 12, 'right': 13, 'is': 14, 'text': 15, 'about': 16, 'on': 17, 'the': 18, 'table': 19, 'captions': 20, 'list': 21, 'figure': 22, 'there': 23, 'existing': 24, 'a': 25, 'content': 26, 'that': 27, 'journal': 28, 'component': 29, '0': 30, 'and': 31, '1': 32, 'if': 33, 'more': 34, 'than': 35, 'one': 36, ',': 37, 'total': 38, 'count': 39, 'both': 40, '2': 41, ';': 42, 'its': 43, 'figure_caption': 44, '3': 45, '0s': 46, 'top-left': 47, 'it': 48, '1s': 49, 'bottom-left': 50, '3s': 51, 's': 52, 'top-right': 53, '2s': 54, 'how': 55, 'many': 56, 'bottom-right': 57, 'any': 58, '4s': 59, 'function': 60, 'title': 61, 'components': 62, 'figures': 63, 'texts': 64, 'figure_captions': 65}\n",
            "66\n",
            "{'Abstract': 0, 'There is no title in the bottom left of page': 1, 'This page is Centered layout': 2, 'There is no title in the top right of page': 3, 'There is no title in the bottom right of page': 4, 'It is unclear': 5, 'Background,Filarial parasites and tissue preparation': 6, 'There is no table_caption in the right of page': 7, 'There is no table_caption in the top right of page': 8, 'There is no table_caption in the bottom right of page': 9, 'There is no figure_caption in the left of page': 10, 'There is no figure_caption in the top left of page': 11, 'There is no figure_caption in the bottom left of page': 12, 'There is no figure_caption in the right of page': 13, 'There is no figure_caption in the top right of page': 14, 'There is no figure_caption in the bottom right of page': 15, 'No (we cannot find the thing meet the requirement)': 16, 'text 1': 17, 'Yes': 18, 'journal': 19, 'No title': 20, 6: 21, 2: 22, 4: 23, 'Yes, it is ': 24, 'There is no title in the left of page': 25, 'There is no title in the top left of page': 26, 'There is no title in the right of page': 27, 'text 0': 28, 'Tissue localization of collagenase and leucine aminopeptidase in the\\nbovine filarial parasite Setaria cervi,Erhöhte urogenitale Fistelrate nach Bevacizumab bei Patientinnen mit rezidiviertem Zervixkarzinom nach primärer Behandlung mit definitiver Radiochemotherapie und bildgesteuerter adaptiver Brachytherapie,Zusammenfassung': 29, 'Zusammenfassung,Abstract': 30, 'Patients,Materials and methods': 31, 'text 6': 32, 'text 9': 33, 'Conclusion': 34}\n",
            "35\n",
            "{'<PAD>': 0, '<UNK>': 1, '<START>': 2, '<END>': 3, 'what': 4, 'titles': 5, 'are': 6, 'left': 7, 'of': 8, 'this': 9, 'page': 10, 'Abstract': 11, 'top': 12, 'bottom': 13, 'There is no title in the bottom left of page': 14, 'right': 15, 'This page is Centered layout': 16, 'There is no title in the top right of page': 17, 'There is no title in the bottom right of page': 18, 'is': 19, 'text': 20, 'about': 21, 'on': 22, 'the': 23, 'It is unclear': 24, 'Background,Filarial parasites and tissue preparation': 25, 'table': 26, 'captions': 27, 'There is no table_caption in the right of page': 28, 'There is no table_caption in the top right of page': 29, 'There is no table_caption in the bottom right of page': 30, 'list': 31, 'figure': 32, 'There is no figure_caption in the left of page': 33, 'There is no figure_caption in the top left of page': 34, 'There is no figure_caption in the bottom left of page': 35, 'There is no figure_caption in the right of page': 36, 'There is no figure_caption in the top right of page': 37, 'There is no figure_caption in the bottom right of page': 38, 'there': 39, 'existing': 40, 'a': 41, 'content': 42, 'that': 43, 'journal': 44, 'component': 45, '0': 46, 'and': 47, '1': 48, 'if': 49, 'more': 50, 'than': 51, 'one': 52, ',': 53, 'total': 54, 'count': 55, 'No (we cannot find the thing meet the requirement)': 56, 'both': 57, '2': 58, 'text 1': 59, ';': 60, 'its': 61, 'figure_caption': 62, '3': 63, '0s': 64, 'top-left': 65, 'it': 66, '1s': 67, 'bottom-left': 68, '3s': 69, 's': 70, 'top-right': 71, 'Yes': 72, '2s': 73, 'how': 74, 'many': 75, 'bottom-right': 76, 'any': 77, '4s': 78, 'function': 79, 'title': 80, 'No title': 81, 'components': 82, 6: 83, 'figures': 84, 2: 85, 'texts': 86, 4: 87, 'figure_captions': 88, 'Yes, it is ': 89, 'There is no title in the left of page': 90, 'There is no title in the top left of page': 91, 'There is no title in the right of page': 92, 'text 0': 93, 'Tissue localization of collagenase and leucine aminopeptidase in the\\nbovine filarial parasite Setaria cervi,Erhöhte urogenitale Fistelrate nach Bevacizumab bei Patientinnen mit rezidiviertem Zervixkarzinom nach primärer Behandlung mit definitiver Radiochemotherapie und bildgesteuerter adaptiver Brachytherapie,Zusammenfassung': 94, 'Zusammenfassung,Abstract': 95, 'Patients,Materials and methods': 96, 'text 6': 97, 'text 9': 98, 'Conclusion': 99}\n",
            "100\n",
            "took 8.94 seconds\n",
            "\u001b[1mVectorizing data...\u001b[0m\n",
            "took 0.00 seconds\n",
            "took \u001b[1m\u001b[34m8.95\u001b[0m seconds\n",
            "\u001b[1mBuilding model...\u001b[0m\n",
            "/content/sample_data/mac-network/ops.py:771: UserWarning: `tf.nn.rnn_cell.BasicRNNCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.SimpleRNNCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  cell = cells[cellType](hDim, reuse = reuse, activation = activation)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:459: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  shape=[input_depth + self._num_units, self._num_units])\n",
            "/usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:463: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  initializer=tf.compat.v1.zeros_initializer(dtype=self.dtype))\n",
            "took \u001b[1m\u001b[34m3.86\u001b[0m seconds\n",
            "2021-11-10 05:21:48.570889: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[1m\u001b[36mRestoring epoch 30 and lr 3.125e-06\u001b[0m\n",
            "\u001b[1m\u001b[34mRestoring weights\u001b[0m\n",
            "Testing on epoch 30...\n",
            "eb \u001b[1m\u001b[32m30\u001b[0m, 49 (\u001b[1m\u001b[32m   50\u001b[0m /    50), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0002\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m0.0014\u001b[0m, avA = \u001b[1m\u001b[31m1.0000\u001b[0m, g = -1.0000, emL = 0.0007, emA = 1.0000; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m30\u001b[0m, 49 (\u001b[1m\u001b[32m   50\u001b[0m /    50), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0006\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.6169\u001b[0m, avA = \u001b[1m\u001b[31m0.8600\u001b[0m, g = -1.0000, emL = 1.0944, emA = 0.9068; clevrExperiment\n",
            "eb \u001b[1m\u001b[32m30\u001b[0m, 49 (\u001b[1m\u001b[32m   50\u001b[0m /    50), t = \u001b[1m\u001b[32m0.01\u001b[0m (0.00+0.01), lr \u001b[1m3.125e-06\u001b[0m, l = \u001b[1m\u001b[34m0.0002\u001b[0m, a = \u001b[1m\u001b[34m1.0000\u001b[0m, avL = \u001b[1m\u001b[34m1.7851\u001b[0m, avA = \u001b[1m\u001b[31m0.8200\u001b[0m, g = -1.0000, emL = 0.9639, emA = 0.9074; clevrExperiment\n",
            "took 4.19 seconds\n",
            "Training EMA Loss: \u001b[1m\u001b[31m0.0013563108277578806\u001b[0m, Training EMA accuracy: \u001b[1m\u001b[31m1.0\u001b[0m\n",
            "Validation Loss: \u001b[1m\u001b[36m1.6169049521369288\u001b[0m, Validation accuracy: \u001b[1m\u001b[36m0.86\u001b[0m\n",
            "Writing predictions...\n",
            "\u001b[1m\u001b[37mDone!\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ujc4fZJfDObX"
      },
      "source": [
        "# !python /content/sample_data/mac-network/main.py --expName \"clevrExperiment\" --outputPreds --testedNum 10 --netLength 4 -r --getPreds --getAtt @/content/sample_data/mac-network/configs/args.txt"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N7LVYMDHYmQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1e984d2-cb23-42c9-ca21-90f435973192"
      },
      "source": [
        "#Visualization\n",
        "!python /content/sample_data/mac-network/visualization.py --expName \"clevrExperiment\" --tier test"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "id: 0\n",
            "img: 0\n",
            "Q: What titles are left of this page?\n",
            "G: There is no title in the left of page\n",
            "P: There is no title in the left of page\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "1\n",
            "id: 1\n",
            "img: 0\n",
            "Q: What titles are top left of this page?\n",
            "G: There is no title in the top left of page\n",
            "P: There is no title in the top left of page\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "2\n",
            "id: 2\n",
            "img: 0\n",
            "Q: What titles are bottom left of this page?\n",
            "G: There is no title in the bottom left of page\n",
            "P: There is no title in the bottom left of page\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "3\n",
            "id: 5\n",
            "img: 0\n",
            "Q: What titles are bottom right of this page?\n",
            "G: There is no title in the bottom right of page\n",
            "P: There is no title in the bottom right of page\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "4\n",
            "id: 6\n",
            "img: 0\n",
            "Q: What is text about on the left of the page?\n",
            "G: text 9\n",
            "P: It is unclear\n",
            "WRONG\n",
            "________________________________________________________________________\n",
            "5\n",
            "id: 7\n",
            "img: 0\n",
            "Q: What is text about on the top left of the page?\n",
            "G: text 9\n",
            "P: It is unclear\n",
            "WRONG\n",
            "________________________________________________________________________\n",
            "6\n",
            "id: 8\n",
            "img: 0\n",
            "Q: What is text about on the bottom left of the page?\n",
            "G: It is unclear\n",
            "P: It is unclear\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "7\n",
            "id: 10\n",
            "img: 0\n",
            "Q: What is text about on the top right of the page?\n",
            "G: It is unclear\n",
            "P: It is unclear\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "8\n",
            "id: 11\n",
            "img: 0\n",
            "Q: What is text about on the bottom right of the page?\n",
            "G: It is unclear\n",
            "P: It is unclear\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "9\n",
            "id: 12\n",
            "img: 0\n",
            "Q: What table captions are left of this page?\n",
            "G: There is no table_caption in the right of page\n",
            "P: There is no table_caption in the right of page\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "10\n",
            "id: 14\n",
            "img: 0\n",
            "Q: What table captions are bottom left of this page?\n",
            "G: There is no table_caption in the bottom right of page\n",
            "P: There is no table_caption in the bottom right of page\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "11\n",
            "id: 15\n",
            "img: 0\n",
            "Q: What table captions are right of this page?\n",
            "G: There is no table_caption in the right of page\n",
            "P: There is no table_caption in the right of page\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "12\n",
            "id: 17\n",
            "img: 0\n",
            "Q: What table captions are bottom right of this page?\n",
            "G: There is no table_caption in the bottom right of page\n",
            "P: There is no table_caption in the bottom right of page\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "13\n",
            "id: 19\n",
            "img: 0\n",
            "Q: What is table about on the top left of the page?\n",
            "G: It is unclear\n",
            "P: It is unclear\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "14\n",
            "id: 20\n",
            "img: 1\n",
            "Q: What is table about on the bottom left of the page?\n",
            "G: It is unclear\n",
            "P: It is unclear\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "15\n",
            "id: 21\n",
            "img: 1\n",
            "Q: What is table about on the right of the page?\n",
            "G: It is unclear\n",
            "P: It is unclear\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "16\n",
            "id: 23\n",
            "img: 1\n",
            "Q: What is table about on the bottom right of the page?\n",
            "G: It is unclear\n",
            "P: It is unclear\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "17\n",
            "id: 24\n",
            "img: 1\n",
            "Q: What is list about on the left of the page?\n",
            "G: Conclusion\n",
            "P: It is unclear\n",
            "WRONG\n",
            "________________________________________________________________________\n",
            "18\n",
            "id: 25\n",
            "img: 1\n",
            "Q: What is list about on the top left of the page?\n",
            "G: Conclusion\n",
            "P: It is unclear\n",
            "WRONG\n",
            "________________________________________________________________________\n",
            "19\n",
            "id: 26\n",
            "img: 1\n",
            "Q: What is list about on the bottom left of the page?\n",
            "G: It is unclear\n",
            "P: It is unclear\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "/content/sample_data/mac-network/visualization.py:141: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig, ax = plt.subplots()\n",
            "/content/sample_data/mac-network/visualization.py:159: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig2, bx = plt.subplots(1, 1) # figsize = figureTableDims\n",
            "20\n",
            "id: 28\n",
            "img: 1\n",
            "Q: What is list about on the top right of the page?\n",
            "G: It is unclear\n",
            "P: It is unclear\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "21\n",
            "id: 29\n",
            "img: 1\n",
            "Q: What is list about on the bottom right of the page?\n",
            "G: It is unclear\n",
            "P: It is unclear\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "22\n",
            "id: 30\n",
            "img: 1\n",
            "Q: What is figure about on the left of the page?\n",
            "G: It is unclear\n",
            "P: It is unclear\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "23\n",
            "id: 31\n",
            "img: 1\n",
            "Q: What is figure about on the top left of the page?\n",
            "G: It is unclear\n",
            "P: It is unclear\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "24\n",
            "id: 33\n",
            "img: 1\n",
            "Q: What is figure about on the right of the page?\n",
            "G: It is unclear\n",
            "P: It is unclear\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "25\n",
            "id: 34\n",
            "img: 1\n",
            "Q: What is figure about on the top right of the page?\n",
            "G: It is unclear\n",
            "P: It is unclear\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "26\n",
            "id: 35\n",
            "img: 1\n",
            "Q: What is figure about on the bottom right of the page?\n",
            "G: It is unclear\n",
            "P: It is unclear\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "27\n",
            "id: 38\n",
            "img: 1\n",
            "Q: What figure captions are bottom left of this page?\n",
            "G: There is no figure_caption in the bottom left of page\n",
            "P: There is no figure_caption in the bottom left of page\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "28\n",
            "id: 40\n",
            "img: 2\n",
            "Q: What figure captions are top right of this page?\n",
            "G: There is no figure_caption in the top right of page\n",
            "P: There is no figure_caption in the top right of page\n",
            "RIGHT\n",
            "________________________________________________________________________\n",
            "29\n",
            "id: 41\n",
            "img: 2\n",
            "Q: What figure captions are bottom right of this page?\n",
            "G: There is no figure_caption in the bottom right of page\n",
            "P: There is no figure_caption in the bottom left of page\n",
            "WRONG\n",
            "________________________________________________________________________\n",
            "30\n",
            "id: 42\n",
            "img: 2\n",
            "Q: How many components are there?\n",
            "G: 2\n",
            "P: 6\n",
            "WRONG\n",
            "________________________________________________________________________\n",
            "31\n",
            "id: 43\n",
            "img: 2\n",
            "Q: How many components are there?\n",
            "G: 2\n",
            "P: 6\n",
            "WRONG\n",
            "________________________________________________________________________\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\", line 1671, in create_block_manager_from_blocks\n",
            "    make_block(values=blocks[0], placement=slice(0, len(axes[0])))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\", line 2744, in make_block\n",
            "    return klass(values, ndim=ndim, placement=placement)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\", line 131, in __init__\n",
            "    f\"Wrong number of items passed {len(self.values)}, \"\n",
            "ValueError: Wrong number of items passed 28, placement implies 27\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/sample_data/mac-network/visualization.py\", line 236, in <module>\n",
            "    main()\n",
            "  File \"/content/sample_data/mac-network/visualization.py\", line 211, in main\n",
            "    showTableAtt(results[i], table, iterations, questionList, \"text\")\n",
            "  File \"/content/sample_data/mac-network/visualization.py\", line 168, in showTableAtt\n",
            "    tableMap = pandas.DataFrame(data = table, index = x, columns = y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\", line 497, in __init__\n",
            "    mgr = init_ndarray(data, index, columns, dtype=dtype, copy=copy)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\", line 234, in init_ndarray\n",
            "    return create_block_manager_from_blocks(block_values, [columns, index])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\", line 1681, in create_block_manager_from_blocks\n",
            "    raise construction_error(tot_items, blocks[0].shape[1:], axes, e)\n",
            "ValueError: Shape of passed values is (4, 28), indices imply (4, 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzbZhk9Do56m"
      },
      "source": [
        "answer = !python /content/sample_data/mac-network/visualization.py --expName \"clevrExperiment\" --tier test "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KsOSDAY2pUJ4",
        "outputId": "520d0de2-7442-49b5-b31d-c2e60fb0d5c6"
      },
      "source": [
        "answer[3][3:-1]"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'What is list about on the top right of the page'"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4bMvv9bQ08N"
      },
      "source": [
        "answersheet = {'What titles are left of this page?':'It is unclear':'There is no title in the left of page',\n",
        "               'What titles are top left of this page?':'There is no title in the top left of page',\n",
        "               'What titles are bottom left of this page':'There is no title in the bottom left of page',\n",
        "               'What titles are bottom right of this page?':'There is no title in the bottom left of page',\n",
        "               'What is text about on the left of the page?':'It is unclear',\n",
        "               'What is text about on the top left of the page?':'It is unclear',\n",
        "               'What is text about on the bottom left of the page?':'It is unclear',\n",
        "               'What is text about on the top right of the page?':'It is unclear',\n",
        "               'What is text about on the bottom right of the page?':'It is unclear',\n",
        "               'What table captions are left of this page?':'There is no table_caption in the right of page',\n",
        "               'What table captions are bottom left of this page?':'There is no table_caption in the bottom right of page',\n",
        "               'What table captions are right of this page?':'There is no table_caption in the right of page',\n",
        "               'What table captions are bottom right of this page?':'There is no table_caption in the bottom right of page',\n",
        "               'What is table about on the top left of the page?':'It is unclear'\n",
        "               }"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXo7QyiS0URD"
      },
      "source": [
        "answersheet2 = {'What is table about on the bottom left of the page?':'It is unclear',\n",
        "               'What is table about on the right of the page?':'It is unclear',\n",
        "               'What is table about on the bottom right of the page?':'It is unclear',\n",
        "               'What is list about on the left of the page?':'It is unclear',\n",
        "                'What is list about on the top left of the page?':'It is unclear',\n",
        "                'What is list about on the bottom left of the page?':'It is unclear',\n",
        "                'What is list about on the top right of the page?':'It is unclear',\n",
        "                'What is list about on the bottom right of the page?':'It is unclear',\n",
        "                'What is figure about on the left of the page?':'It is unclear',\n",
        "                'What is figure about on the top left of the page?':'It is unclear',\n",
        "                'What is figure about on the right of the page?':'It is unclear',\n",
        "                'What is figure about on the top right of the page?':'It is unclear',\n",
        "                'What is figure about on the bottom right of the page?':'It is unclear',\n",
        "                'What figure captions are bottom left of this page?':'There is no figure_caption in the bottom left of page'\n",
        "               }"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LdGfShuAtLt"
      },
      "source": [
        "answersheet3 = {'What figure captions are top right of this page?':'There is no figure_caption in the top right of page',\n",
        "               'What figure captions are bottom right of this page?':'There is no figure_caption in the bottom left of page',\n",
        "               'How many components are there?':'6'\n",
        "               }"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlm2fsEZ2qct"
      },
      "source": [
        "# save model \n",
        "# import pickle\n",
        "# file_name = \"model.pkl\"\n",
        "# with open(file_name,'wb') as file:\n",
        "#   pickle.dump(model, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf0RsPzS0EQw"
      },
      "source": [
        "# Flask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSdn9MYTz0bz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97218800-a1ad-43fa-90dc-f6f6e389ef2a"
      },
      "source": [
        "from flask import Flask, render_template\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, request, render_template\n",
        "\n",
        "app = Flask(__name__, template_folder='/content/sample_data')\n",
        "run_with_ngrok(app) \n",
        "@app.route(\"/\", methods=('GET','POST'))\n",
        "def home():\n",
        "    return render_template('homepage.html')\n",
        "@app.route(\"/index\", methods=('GET','POST'))\n",
        "\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "@app.route(\"/index2\", methods=('GET','POST'))\n",
        "def index2():\n",
        "    return render_template('index2.html')\n",
        "@app.route(\"/index3\", methods=('GET','POST'))\n",
        "def index3():\n",
        "    return render_template('index3.html')\n",
        "# @app.route('/11111') #页面链接该路由名称\n",
        "# def f_infor():\n",
        "#     return render_template('11111.html')\n",
        "# @app.route('/22222') #页面链接该路由名称\n",
        "# def y_infor():\n",
        "#     return render_template('22222.html')\n",
        "@app.route('/getpredictionMAC',methods=['POST'])\n",
        "def getpredictionMAC():    \n",
        "    input = [str(x) for x in request.form.values()]\n",
        "    final_input = input\n",
        "    output1 = answersheet[final_input[0]]\n",
        "    # return render_template('index.html', output='Predicted Weight in KGs :{}'.format(output1))\n",
        "    return output1\n",
        "@app.route('/getpredictionLM',methods=['POST'])\n",
        "def getpredictionLM():    \n",
        "    input = [str(x) for x in request.form.values()]\n",
        "    final_input = input\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "    question=final_input\n",
        "\n",
        "    image=Image.open(\"/content/sample_data/CLEVR_v1/images/test/CLEVR_test_000000.png\").convert(\"RGB\")\n",
        "\n",
        "    processor = LayoutLMv2Processor.from_pretrained(\"microsoft/layoutlmv2-base-uncased\")\n",
        "\n",
        "    encoding = processor(image, question, return_tensors=\"pt\",truncation=True,max_length=512)\n",
        "    # # NEW ADD\n",
        "    # model = torch.load('/content/sample_data/model.pkl')\n",
        "    for k,v in encoding.items():\n",
        "      encoding[k] = v.to(QAmodel.device)\n",
        "    outputs = QAmodel(**encoding)\n",
        "    start_logits = outputs.start_logits\n",
        "    end_logits = outputs.end_logits\n",
        "    predicted_start_idx = start_logits.argmax(-1).item()\n",
        "    predicted_end_idx = end_logits.argmax(-1).item()\n",
        "    output1 = processor.tokenizer.decode(encoding.input_ids.squeeze()[predicted_start_idx:predicted_end_idx+1])\n",
        "    # return render_template('index.html', output='Predicted Weight in KGs :{}'.format(output1))\n",
        "    return output1\n",
        "\n",
        "@app.route('/getpredictionMAC2',methods=['POST'])\n",
        "def getpredictionMAC2():    \n",
        "    input = [str(x) for x in request.form.values()]\n",
        "    final_input = input\n",
        "    output1 = answersheet2[final_input[0]]\n",
        "    # return render_template('index.html', output='Predicted Weight in KGs :{}'.format(output1))\n",
        "    return output1\n",
        "@app.route('/getpredictionLM2',methods=['POST'])\n",
        "def getpredictionLM2():    \n",
        "    input = [str(x) for x in request.form.values()]\n",
        "    final_input = input\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "    question=final_input\n",
        "\n",
        "    image=Image.open(\"/content/sample_data/CLEVR_v1/images/test/CLEVR_test_000001.png\").convert(\"RGB\")\n",
        "\n",
        "    processor = LayoutLMv2Processor.from_pretrained(\"microsoft/layoutlmv2-base-uncased\")\n",
        "\n",
        "    encoding = processor(image, question, return_tensors=\"pt\",truncation=True,max_length=512)\n",
        "    # # NEW ADD\n",
        "    # model = torch.load('/content/sample_data/model.pkl')\n",
        "    for k,v in encoding.items():\n",
        "      encoding[k] = v.to(QAmodel.device)\n",
        "    outputs = QAmodel(**encoding)\n",
        "    start_logits = outputs.start_logits\n",
        "    end_logits = outputs.end_logits\n",
        "    predicted_start_idx = start_logits.argmax(-1).item()\n",
        "    predicted_end_idx = end_logits.argmax(-1).item()\n",
        "    output1 = processor.tokenizer.decode(encoding.input_ids.squeeze()[predicted_start_idx:predicted_end_idx+1])\n",
        "    # return render_template('index.html', output='Predicted Weight in KGs :{}'.format(output1))\n",
        "    return output1\n",
        "\n",
        "@app.route('/getpredictionMAC3',methods=['POST'])\n",
        "def getpredictionMAC3():    \n",
        "    input = [str(x) for x in request.form.values()]\n",
        "    final_input = input\n",
        "    output1 = answersheet3[final_input[0]]\n",
        "    # return render_template('index.html', output='Predicted Weight in KGs :{}'.format(output1))\n",
        "    return output1\n",
        "@app.route('/getpredictionLM3',methods=['POST'])\n",
        "def getpredictionLM3():    \n",
        "    input = [str(x) for x in request.form.values()]\n",
        "    final_input = input\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "    question=final_input\n",
        "\n",
        "    image=Image.open(\"/content/sample_data/CLEVR_v1/images/test/CLEVR_test_000002.png\").convert(\"RGB\")\n",
        "\n",
        "    processor = LayoutLMv2Processor.from_pretrained(\"microsoft/layoutlmv2-base-uncased\")\n",
        "\n",
        "    encoding = processor(image, question, return_tensors=\"pt\",truncation=True,max_length=512)\n",
        "    # # NEW ADD\n",
        "    # model = torch.load('/content/sample_data/model.pkl')\n",
        "    for k,v in encoding.items():\n",
        "      encoding[k] = v.to(QAmodel.device)\n",
        "    outputs = QAmodel(**encoding)\n",
        "    start_logits = outputs.start_logits\n",
        "    end_logits = outputs.end_logits\n",
        "    predicted_start_idx = start_logits.argmax(-1).item()\n",
        "    predicted_end_idx = end_logits.argmax(-1).item()\n",
        "    output1 = processor.tokenizer.decode(encoding.input_ids.squeeze()[predicted_start_idx:predicted_end_idx+1])\n",
        "    # return render_template('index.html', output='Predicted Weight in KGs :{}'.format(output1))\n",
        "    return output1\n",
        "app.run()"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://ffca-34-91-14-38.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [10/Nov/2021 08:47:54] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [10/Nov/2021 08:47:55] \"\u001b[33mGET /resources/sheet.css HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [10/Nov/2021 08:47:58] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [10/Nov/2021 08:48:01] \"\u001b[37mGET /index HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [10/Nov/2021 08:48:16] \"\u001b[37mPOST /getpredictionLM HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        }
      ]
    }
  ]
}